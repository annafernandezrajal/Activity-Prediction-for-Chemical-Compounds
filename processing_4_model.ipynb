{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import rdkit.Chem.rdMolDescriptors as d\n",
    "import rdkit.Chem.Fragments as f\n",
    "import rdkit.Chem.Lipinski as l\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromSmiles('Cc1ccccc1')\n",
    "m.GetNumAtoms()\n",
    "# rdMolDescriptors\n",
    "d.CalcExactMolWt(m)\n",
    "# Fragments\n",
    "f.fr_Al_COO(m)\n",
    "# Lipinski \n",
    "l.HeavyAtomCount(m)\n",
    "# Fingerprints\n",
    "fp = AllChem.GetMorganFingerprintAsBitVect(m,2,nBits=124)\n",
    "np.array(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_smiles.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "# df['molwt'] = df['mol'].apply(d.CalcExactMolWt)\n",
    "# df['fr_Al_COO'] = df['mol'].apply(f.fr_Al_COO)\n",
    "# df['HeavyAtomCount'] = df['mol'].apply(l.HeavyAtomCount)\n",
    "# df['fp'] = df['mol'].apply(lambda x: AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES WITHIN EACH ATOM\n",
    "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2523-5/tables/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['most_common_atom'] = df['mol'].apply(lambda x: x.Chem.GetAtomWithIdx(x.GetMostCommonAtomIdx()).GetSymbol())\n",
    "df['number_atoms'] = df['mol'].apply(Chem.GetNumAtoms)\n",
    "df['number_hydrogen'] = df['mol'].GetNumHeavyAtoms()\n",
    "df['unsaturation'] = df['mol'].GetNumHeteroatoms()\n",
    "df['formal_charge'] = df['mol'].GetFormalCharge()\n",
    "df['total_valence'] = df['mol'].GetTotalValence()\n",
    "df['ring'] = df['mol'].IsInRing()\n",
    "df['aromatic_atoms'] = df['mol'].GetAromaticAtoms()\n",
    "df['chirality_atoms'] = df['mol'].GetChiralAtoms()\n",
    "df['hybridization_atoms'] = df['mol'].GetHybridizationAtoms()\n",
    "\n",
    "df.to_csv('training_processed_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES WITHIN EACH SMILE\n",
    "\n",
    "https://aip.scitation.org/doi/pdf/10.1063/1.5062773 --> 11 features extracted out of the number of elements of a certain type in the bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smiles_length'] = df['SMILES'].apply(len)\n",
    "df['number_atoms'] = df['mol'].apply(lambda x: x.GetNumAtoms()) # number of atoms in the molecule\n",
    "df['number_bonds'] = df['mol'].apply(lambda x: x.GetNumBonds())\n",
    "df['number_carbon_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 6]))\n",
    "df['number_nitrogen_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 7]))\n",
    "df['number_potasium_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 19]))\n",
    "df['number_sulfur_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 16]))\n",
    "df['number_clorine_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 17]))\n",
    "df['number_bromine_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 35]))\n",
    "df['number_iodine_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 53]))\n",
    "df['number_oxygen_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 8]))\n",
    "\n",
    "# --- not included in paper\n",
    "df['number_hydrogen_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 1]))\n",
    "df['number_fluorine_atoms'] = df['mol'].apply(lambda x: len([atom for atom in x.GetAtoms() if atom.GetAtomicNum() == 9]))\n",
    "\n",
    "\n",
    "df.to_csv('training_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DIVIDE TRAINING AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get the features and labels\n",
    "data = pd.read_csv('training_preprocessed.csv')\n",
    "features = data.drop(['SMILES', 'mol', 'ACTIVE', 'INDEX'], axis=1)\n",
    "labels = data['ACTIVE']\n",
    "\n",
    "features = features.loc[:, (features != 0).any(axis=0)] # drop columns with all zeros\n",
    "features = features.dropna(axis=1, how='all') # drop columns with all Nan\n",
    "\n",
    "data_train, data_valid, labels_train, labels_valid = train_test_split(features, labels, test_size=0.25, random_state=20) # change random_state to get different results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLY MINMAX SCALER; STANDART SCALER AND PCA\n",
    "\n",
    "After dividing the training data into training and validation, we applied a minmax scaler, followed by a standart scaler and pca into the training badge. After we used those scalers and pca to apply the same transformation used for training into the validation set. \n",
    "The scalers and pca were fitted only with the training data, and then applied also to validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add functions from previous assignments\n",
    "import functions as f\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "mm = preprocessing.MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "pca = PCA(n_components=0.95) #scikit-learn choose the minimum number of principal components such that 95% of the variance is retained\n",
    "\n",
    "\n",
    "def pre_process(df, labels, mm, ss, pca, train=True):\n",
    "    features_processed = df.loc[:, (df != 0).any(axis=0)] # drop columns with all zeros\n",
    "    features_processed = features_processed.dropna(axis=1, how='all') # drop columns with all Nan\n",
    "    # save index from features_processed\n",
    "    index = features_processed.index\n",
    "\n",
    "    if train==True:\n",
    "        features_processed = mm.fit_transform(features_processed)\n",
    "        features_processed = ss.fit_transform(features_processed)\n",
    "        features_processed = pca.fit_transform(features_processed)\n",
    "    else :\n",
    "        features_processed = mm.transform(features_processed)\n",
    "        features_processed = ss.transform(features_processed)\n",
    "        features_processed = pca.transform(features_processed)\n",
    "\n",
    "    features_processed = pd.DataFrame(features_processed, index)\n",
    "    features_processed.columns = ['feature_' + str(i) for i in range(1, len(features_processed.columns)+1)]\n",
    "\n",
    "    return features_processed, labels\n",
    "\n",
    "features_processed_train, labels_train = pre_process(data_train, labels_train, mm, ss, pca, train=True)\n",
    "features_processed_valid, labels_valid = pre_process(data_valid, labels_valid, mm, ss, pca, train=False) #apply pca to data_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the training processed data with its corresponding labels.\n",
    "Saved the validation processed data (with the processing tools fitted to the training set) and saved with the corresponding labels, which should be used as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_processed = features_processed_train\n",
    "training_processed['ACTIVE'] = labels_train\n",
    "training_processed.to_csv('training_processed.csv', index=False)\n",
    "\n",
    "validation_processed = features_processed_valid\n",
    "validation_processed['ACTIVE'] = labels_valid\n",
    "validation_processed.to_csv('validation_processed.csv', index=False)\n",
    "\n",
    "\n",
    "# TOTAL PROCESSED WITH TRAINING AND VALIDATION PCA applied only on training data, then applied on validation data\n",
    "validation_true = validation_processed.copy()\n",
    "validation_true['ACTIVE'] = labels_valid\n",
    "total_processed = training_processed.append(validation_true)\n",
    "total_processed.to_csv('total_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (only to check) LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score   \n",
    "\n",
    "data_train = pd.read_csv('training_processed.csv')\n",
    "data_valid = pd.read_csv('validation_processed.csv')\n",
    "\n",
    "labels_train = data_train['ACTIVE']# ground truth labels\n",
    "features_train = data_train.drop(['ACTIVE'], axis=1) \n",
    "labels_valid = data_valid['ACTIVE']# ground truth labels\n",
    "features_valid = data_valid.drop(['ACTIVE'], axis=1)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# Train \n",
    "logisticRegr.fit(features_train, labels_train)\n",
    "\n",
    "# Predict\n",
    "log_labels = logisticRegr.predict(features_valid)# predicted labels\n",
    "log_score = logisticRegr.score(features_valid, labels_valid)\n",
    "log_pred = logisticRegr.predict_proba(features_valid)\n",
    "\n",
    "log_auc = roc_auc_score(labels_valid, log_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('Logistic Regression Accuracy: ', log_score)\n",
    "print('Logistic Regression AUC: ', log_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score   \n",
    "\n",
    "data_train = pd.read_csv('training_processed.csv')\n",
    "data_valid = pd.read_csv('validation_processed.csv')\n",
    "\n",
    "labels_train = data_train['ACTIVE']# ground truth labels\n",
    "features_train = data_train.drop(['ACTIVE'], axis=1) \n",
    "labels_valid = data_valid['ACTIVE']# ground truth labels\n",
    "features_valid = data_valid.drop(['ACTIVE'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.9886855241264559\n",
      "Logistic Regression AUC:  0.7578277337651416\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# Train \n",
    "logisticRegr.fit(features_train, labels_train)\n",
    "\n",
    "# Predict\n",
    "log_labels = logisticRegr.predict(features_valid)# predicted labels\n",
    "log_score = logisticRegr.score(features_valid, labels_valid)\n",
    "log_pred = logisticRegr.predict_proba(features_valid)\n",
    "\n",
    "log_auc = roc_auc_score(labels_valid, log_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('Logistic Regression Accuracy: ', log_score)\n",
    "print('Logistic Regression AUC: ', log_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.SVC(probability=True)\n",
    "\n",
    "# Train\n",
    "svm_clf.fit(features_train, labels_train)\n",
    "\n",
    "# Predict\n",
    "svm_labels = svm_clf.predict(features_valid)# predicted labels\n",
    "svm_score = svm_clf.score(features_valid, labels_valid)\n",
    "svm_pred = svm_clf.predict_proba(features_valid)\n",
    "\n",
    "svm_auc = roc_auc_score(labels_valid, svm_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('SVM Accuracy: ', svm_score)\n",
    "print('SVM AUC: ', svm_auc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_clf = svm.SVC(probability=True)\n",
    "SVM Accuracy:  0.9887879175732753\n",
    "SVM AUC:  0.5164718458815745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.9685396134647383\n",
      "Naive Bayes AUC:  0.737215835375757\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Train \n",
    "naive_bayes.fit(features_train, labels_train)\n",
    "\n",
    "# Predict\n",
    "naive_bayes_labels = naive_bayes.predict(features_valid)# predicted labels\n",
    "naive_bayes_score = naive_bayes.score(features_valid, labels_valid)\n",
    "naive_bayes_pred = naive_bayes.predict_proba(features_valid)\n",
    "\n",
    "\n",
    "naive_bayes_auc = roc_auc_score(labels_valid, naive_bayes_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "\n",
    "print('Naive Bayes Accuracy: ', naive_bayes_score)\n",
    "print('Naive Bayes AUC: ', naive_bayes_auc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive_bayes = GaussianNB()\n",
    "Naive Bayes Accuracy:  0.9685396134647383\n",
    "Naive Bayes AUC:  0.737215835375757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(features_train, labels_train)\n",
    "knn_labels = knn.predict(features_valid)# predicted labels\n",
    "knn_score = knn.score(features_valid, labels_valid)\n",
    "knn_pred = knn.predict_proba(features_valid)\n",
    "\n",
    "knn_auc = roc_auc_score(labels_valid, knn_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('KNN Accuracy: ', knn_score)\n",
    "print('KNN AUC: ', knn_auc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neighbors = 3\n",
    "KNN Accuracy:  0.9879175732753104\n",
    "KNN AUC:  0.5483442627078582\n",
    "\n",
    "neighbors = 5\n",
    "KNN Accuracy:  0.9886343274030462\n",
    "KNN AUC:  0.5604776061602166\n",
    "\n",
    "neighbors = 7\n",
    "KNN Accuracy:  0.9887623192115704\n",
    "KNN AUC:  0.5723251994576865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=100, alpha=0.0001)\n",
    "ann.fit(features_train, labels_train)\n",
    "ann_labels = ann.predict(features_valid)# predicted labels\n",
    "ann_score = ann.score(features_valid, labels_valid)\n",
    "ann_pred = ann.predict_proba(features_valid)\n",
    "\n",
    "ann_auc = roc_auc_score(labels_valid, ann_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('ANN Accuracy: ', ann_score)\n",
    "print('ANN AUC: ', ann_auc)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden_layer_sizes=(100, 100, 100), max_iter=100, alpha=0.0001)\n",
    "ANN Accuracy:  0.9881223601689492\n",
    "ANN AUC:  0.7085456584949629\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(features_train, labels_train)\n",
    "dec_tree_labels = dec_tree.predict(features_valid)# predicted labels\n",
    "dec_tree_score = dec_tree.score(features_valid, labels_valid)\n",
    "dec_tree_pred = dec_tree.predict_proba(features_valid)\n",
    "\n",
    "dec_tree_auc = roc_auc_score(labels_valid, dec_tree_pred[:,1])\n",
    "\n",
    "# print the results \n",
    "print('Decision Tree Accuracy: ', dec_tree_score)\n",
    "print('Decision Tree AUC: ', dec_tree_auc)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dec_tree = DecisionTreeClassifier()\n",
    "Decision Tree Accuracy:  0.9817227697427364\n",
    "Decision Tree AUC:  0.5279052211450267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy:  0.9886855241264559\n",
      "XGBoost AUC:  0.7504152523969736\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(features_train, labels_train)\n",
    "xgb_labels = xgb.predict(features_valid)# predicted labels\n",
    "xgb_score = xgb.score(features_valid, labels_valid)\n",
    "xgb_pred = xgb.predict_proba(features_valid)\n",
    "\n",
    "xgb_auc = roc_auc_score(labels_valid, xgb_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('XGBoost Accuracy: ', xgb_score)\n",
    "print('XGBoost AUC: ', xgb_auc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb = XGBClassifier()\n",
    "XGBoost Accuracy:  0.9886855241264559\n",
    "XGBoost AUC:  0.7504152523969736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.98712402406246\n",
      "Random Forest AUC:  0.679924037566644\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(features_train, labels_train)\n",
    "rf_labels = rf.predict(features_valid)# predicted labels\n",
    "rf_score = rf.score(features_valid, labels_valid)\n",
    "rf_pred = rf.predict_proba(features_valid)\n",
    "\n",
    "rf_auc = roc_auc_score(labels_valid, rf_pred[:,1])\n",
    "\n",
    "# print the results\n",
    "print('Random Forest Accuracy: ', rf_score)\n",
    "print('Random Forest AUC: ', rf_auc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators = 100\n",
    "Random Forest Accuracy:  0.9869960322539357\n",
    "Random Forest AUC:  0.6720564956043119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87aa02f59f11f203877f84b7d45764aaf13360db5b8989584dc8f31b39de343b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
